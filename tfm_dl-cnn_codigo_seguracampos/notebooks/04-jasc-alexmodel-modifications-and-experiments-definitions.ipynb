{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cdfdc9-c04b-4987-ac77-65057326f9a5",
   "metadata": {},
   "source": [
    "# AlexNet Model\n",
    "A. Krizhevsky et al. described their architecture as:\n",
    "* \"The first convolutional layer filters the 224x224 input image with 96 kernels of size 11x11 wit a stride of 4 pixels.\"\n",
    "* Then, \"the second convolutional layer takes as input the (response-pooled) output of the first convolutional layer and it filters it with 256 kernels if size 5x5.\n",
    "* \"The third, fourth, and fifth convolutional layers are connected to one another without any intervening pooling layers\"\n",
    "    * \"The third convolutional layer has 384 kernels of size 3x3 connected to the outputs of the second layer\"\n",
    "    * \"The fourth convolutional layer has 384 kernels of size 3x3\"\n",
    "    * \"The fifth layer has 256 layers of size 3x3\"\n",
    "* The fully-connected layers have 4096 neurons each.\n",
    "\n",
    "A. Krizhevsky et al. also, defined that after each convolutional layer a ReLu function is applied to the outputs.\n",
    "\n",
    "**Pooling** is applied to the after the first, second and fifth layers (A. Krizhevsky et al. 2017).\n",
    "\n",
    "**Dropout** is also applied before and after the first fully connected layer to avoid *overfitting* (A. Krizhevsky et al. 2017).\n",
    "\n",
    "The model called \"AlexNet\" is defined in Python with Pytorch in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b57caf-5968-4760-b24f-0b02fb7d4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jascrer/anaconda3/envs/TFM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the definition of the AlexNet which will be compared to the Phi-LetNet-5.\n",
    "    This AlexNet will be modified in order to classify just two classes.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=6400, out_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096,out_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_parameter):\n",
    "        \"\"\"\n",
    "        Data processing method\n",
    "        \"\"\"\n",
    "        x_parameter = self.features(x_parameter)\n",
    "        x_parameter = self.flatten(x_parameter)\n",
    "        x_parameter = self.classifier(x_parameter)\n",
    "        return x_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e02eb-6308-4555-bf98-0609bd4e7cf8",
   "metadata": {},
   "source": [
    "In the class constructor, the class defines 3 properties called features, flatten and classifier.\n",
    "\n",
    "**Features** contains the definition for the convolutional and max pooling layers.\n",
    "\n",
    "**Flatten** defines a flattening layer before the fully connected layers.\n",
    "\n",
    "**Classifier** contains the three fully-connected and dropout layers with the specified inputs. And in order to classify the images in the two categories of the experiment (HAS_CACTUS, NO_CACTUS), a LogSoftmax function that is applied to the output of the fully connected layers to provide the normalized probability distribution as a result like in the definition of E. López-Jiménez, et al.\n",
    "\n",
    "The *forward* method contains the flow in which the inputs will be processed:\n",
    "* First, the inputs are processed by the convolutional and max pooling layers (features)\n",
    "* Then, the output will be flatten to then\n",
    "* Be fed to the classifier to determine the category they will be in.\n",
    "\n",
    "\n",
    "## Execution Parameters\n",
    "For this model, the hyperparameters defined by E. López-Jiménez, et al. were tested for training, but when the training was executed, Pytorch warned that it was not possible to use a batch size of 2500, instead the batch size was reduced to 250 units. The epoch number remained at 150, and the learning rate was diminished to 0.001. This reduction will be explained in the results section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f0c02c-1975-4354-b7f4-f2f31da3b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCH_COUNT = 150\n",
    "BATCH_SIZE = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d7026-1e2b-498f-8089-32cd85ea50cb",
   "metadata": {},
   "source": [
    "## Execution Times\n",
    "This model posseses execution times between 2 hours and 2 hours and 30 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae977b7-86cf-4ad5-884a-5fa21b0648ae",
   "metadata": {},
   "source": [
    "# References\n",
    "* López-Jiménez, Efren; Vasquez-Gomez, Juan Irving; Sanchez-Acevedo, Miguel Angel; Herrera-Lozada, Juan Carlos; Uriarte-Arcia, Abril Valeria (2019); “Columnar Cactus Recognition in Aerial Images using a Deep Learning Approach”. Ecological Informatics. 52. 131-138.\n",
    "* Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E. (2017-05-24); \"ImageNet classification with deep convolutional neural networks\" (PDF). Communications of the ACM. 60 (6): 84–90. doi:10.1145/3065386. ISSN 0001-0782."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
